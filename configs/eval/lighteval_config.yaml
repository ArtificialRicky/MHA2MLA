# As of right now auto batch size doesn't work, so we use some default
batch_size: 8
generation: null
logging:
  output_dir: "outputs"
  save_details: true
  push_to_hub: false
  public_run: false
  results_org: null
  tensorboard_metric_prefix: "eval"
parallelism:
  dp: 3
  pp: 1
  pp_engine: 1f1b
  tp: 1
  tp_linear_async_communication: false
  tp_mode: ALL_REDUCE
tasks:
  dataset_loading_processes: 1
  multichoice_continuations_start_space: null
  num_fewshot_seeds: null
  custom_tasks: ../src/evaluation/tasks.py
  # tasks: "custom|openbook_qa|0|1,custom|winogrande|0|1"
  tasks: "custom|hellaswag|0|1,custom|arc|0|1,custom|piqa|0|1,custom|mmlu_pro|0|1,custom|trivia_qa|0|1,custom|winogrande|0|1,custom|openbook_qa|0|1"