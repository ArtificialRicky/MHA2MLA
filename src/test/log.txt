INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 192]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 3317760, W_v: 3317760
INFO:root:err_norm_K: ['7.026e-04', '6.551e-04', '6.551e-04', '6.939e-04', '6.551e-04', '7.279e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.248e-04', '7.336e-04', '7.000e-04']
INFO:root:err_norm: ['7.117e-04', '6.776e-04', '6.776e-04', '7.094e-04', '6.943e-04', '7.140e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-360M
INFO:root:r: 8
INFO:root:#layer: 32, shape of W_k: torch.Size([960, 320]) W_v: torch.Size([960, 320])
INFO:root:Total number of parameters in W_k: 9830400, W_v: 9830400
INFO:root:err_norm_K: ['4.226e-04', '4.040e-04', '4.040e-04', '4.200e-04', '4.040e-04', '4.346e-04']
INFO:root:err_norm_V: ['4.440e-04', '4.352e-04', '4.352e-04', '4.455e-04', '4.496e-04', '4.352e-04']
INFO:root:err_norm: ['4.333e-04', '4.196e-04', '4.196e-04', '4.327e-04', '4.268e-04', '4.349e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-1.7B
INFO:root:r: 8
INFO:root:#layer: 24, shape of W_k: torch.Size([2048, 2048]) W_v: torch.Size([2048, 2048])
INFO:root:Total number of parameters in W_k: 100663296, W_v: 100663296
INFO:root:err_norm_K: ['6.723e-05', '6.521e-05', '6.521e-05', '6.672e-05', '6.521e-05', '6.820e-05']
INFO:root:err_norm_V: ['6.398e-05', '6.342e-05', '6.342e-05', '6.421e-05', '6.420e-05', '6.342e-05']
INFO:root:err_norm: ['6.561e-05', '6.431e-05', '6.431e-05', '6.546e-05', '6.470e-05', '6.581e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-1B
INFO:root:r: 8
INFO:root:#layer: 16, shape of W_k: torch.Size([2048, 512]) W_v: torch.Size([2048, 512])
INFO:root:Total number of parameters in W_k: 16777216, W_v: 16777216
INFO:root:err_norm_K: ['3.490e-05', '3.358e-05', '3.358e-05', '3.439e-05', '3.358e-05', '3.590e-05']
INFO:root:err_norm_V: ['1.353e-05', '1.334e-05', '1.334e-05', '1.380e-05', '1.367e-05', '1.334e-05']
INFO:root:err_norm: ['2.422e-05', '2.346e-05', '2.346e-05', '2.410e-05', '2.362e-05', '2.462e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-3B
INFO:root:r: 8
INFO:root:#layer: 28, shape of W_k: torch.Size([3072, 1024]) W_v: torch.Size([3072, 1024])
INFO:root:Total number of parameters in W_k: 88080384, W_v: 88080384
INFO:root:err_norm_K: ['1.705e-05', '1.667e-05', '1.667e-05', '1.691e-05', '1.667e-05', '1.733e-05']
INFO:root:err_norm_V: ['8.388e-06', '8.326e-06', '8.326e-06', '8.462e-06', '8.421e-06', '8.326e-06']
INFO:root:err_norm: ['1.272e-05', '1.250e-05', '1.250e-05', '1.269e-05', '1.254e-05', '1.283e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.1-8B
INFO:root:r: 8
INFO:root:#layer: 32, shape of W_k: torch.Size([4096, 1024]) W_v: torch.Size([4096, 1024])
INFO:root:Total number of parameters in W_k: 134217728, W_v: 134217728
INFO:root:err_norm_K: ['1.266e-05', '1.243e-05', '1.243e-05', '1.258e-05', '1.243e-05', '1.285e-05']
INFO:root:err_norm_V: ['5.329e-06', '5.292e-06', '5.292e-06', '5.381e-06', '5.354e-06', '5.292e-06']
INFO:root:err_norm: ['8.997e-06', '8.860e-06', '8.860e-06', '8.979e-06', '8.891e-06', '9.069e-06']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 192]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 3317760, W_v: 3317760
INFO:root:err_norm_K: ['6.777e-04', '5.982e-04', '5.982e-04', '6.666e-04', '5.982e-04', '7.188e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.090e-04', '7.264e-04', '6.640e-04']
INFO:root:err_norm: ['6.906e-04', '6.311e-04', '6.311e-04', '6.878e-04', '6.623e-04', '6.914e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-360M
INFO:root:r: 16
INFO:root:#layer: 32, shape of W_k: torch.Size([960, 320]) W_v: torch.Size([960, 320])
INFO:root:Total number of parameters in W_k: 9830400, W_v: 9830400
INFO:root:err_norm_K: ['4.117e-04', '3.803e-04', '3.803e-04', '4.083e-04', '3.803e-04', '4.308e-04']
INFO:root:err_norm_V: ['4.366e-04', '4.200e-04', '4.200e-04', '4.387e-04', '4.465e-04', '4.200e-04']
INFO:root:err_norm: ['4.242e-04', '4.002e-04', '4.002e-04', '4.235e-04', '4.134e-04', '4.254e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-1.7B
INFO:root:r: 16
INFO:root:#layer: 24, shape of W_k: torch.Size([2048, 2048]) W_v: torch.Size([2048, 2048])
INFO:root:Total number of parameters in W_k: 100663296, W_v: 100663296
INFO:root:err_norm_K: ['6.627e-05', '6.314e-05', '6.314e-05', '6.556e-05', '6.314e-05', '6.760e-05']
INFO:root:err_norm_V: ['6.353e-05', '6.249e-05', '6.249e-05', '6.386e-05', '6.390e-05', '6.249e-05']
INFO:root:err_norm: ['6.490e-05', '6.281e-05', '6.281e-05', '6.471e-05', '6.352e-05', '6.504e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-1B
INFO:root:r: 16
INFO:root:#layer: 16, shape of W_k: torch.Size([2048, 512]) W_v: torch.Size([2048, 512])
INFO:root:Total number of parameters in W_k: 16777216, W_v: 16777216
INFO:root:err_norm_K: ['3.426e-05', '3.223e-05', '3.223e-05', '3.351e-05', '3.223e-05', '3.573e-05']
INFO:root:err_norm_V: ['1.337e-05', '1.301e-05', '1.301e-05', '1.381e-05', '1.362e-05', '1.301e-05']
INFO:root:err_norm: ['2.382e-05', '2.262e-05', '2.262e-05', '2.366e-05', '2.292e-05', '2.437e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-3B
INFO:root:r: 16
INFO:root:#layer: 28, shape of W_k: torch.Size([3072, 1024]) W_v: torch.Size([3072, 1024])
INFO:root:Total number of parameters in W_k: 88080384, W_v: 88080384
INFO:root:err_norm_K: ['1.686e-05', '1.626e-05', '1.626e-05', '1.665e-05', '1.626e-05', '1.726e-05']
INFO:root:err_norm_V: ['8.335e-06', '8.218e-06', '8.218e-06', '8.455e-06', '8.396e-06', '8.218e-06']
INFO:root:err_norm: ['1.260e-05', '1.224e-05', '1.224e-05', '1.255e-05', '1.233e-05', '1.274e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.1-8B
INFO:root:r: 16
INFO:root:#layer: 32, shape of W_k: torch.Size([4096, 1024]) W_v: torch.Size([4096, 1024])
INFO:root:Total number of parameters in W_k: 134217728, W_v: 134217728
INFO:root:err_norm_K: ['1.253e-05', '1.215e-05', '1.215e-05', '1.240e-05', '1.215e-05', '1.281e-05']
INFO:root:err_norm_V: ['5.297e-06', '5.227e-06', '5.227e-06', '5.383e-06', '5.342e-06', '5.227e-06']
INFO:root:err_norm: ['8.914e-06', '8.690e-06', '8.690e-06', '8.889e-06', '8.747e-06', '9.019e-06']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 32
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 192]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 3317760, W_v: 3317760
INFO:root:err_norm_K: ['6.410e-04', '5.092e-04', '5.092e-04', '6.282e-04', '5.092e-04', '7.032e-04']
INFO:root:err_norm_V: ['6.729e-04', '5.971e-04', '5.971e-04', '6.794e-04', '7.108e-04', '5.971e-04']
INFO:root:err_norm: ['6.569e-04', '5.532e-04', '5.532e-04', '6.538e-04', '6.100e-04', '6.502e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-360M
INFO:root:r: 32
INFO:root:#layer: 32, shape of W_k: torch.Size([960, 320]) W_v: torch.Size([960, 320])
INFO:root:Total number of parameters in W_k: 9830400, W_v: 9830400
INFO:root:err_norm_K: ['3.950e-04', '3.425e-04', '3.425e-04', '3.908e-04', '3.425e-04', '4.242e-04']
INFO:root:err_norm_V: ['4.234e-04', '3.919e-04', '3.919e-04', '4.260e-04', '4.400e-04', '3.919e-04']
INFO:root:err_norm: ['4.092e-04', '3.672e-04', '3.672e-04', '4.084e-04', '3.913e-04', '4.081e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-1.7B
INFO:root:r: 32
INFO:root:#layer: 24, shape of W_k: torch.Size([2048, 2048]) W_v: torch.Size([2048, 2048])
INFO:root:Total number of parameters in W_k: 100663296, W_v: 100663296
INFO:root:err_norm_K: ['6.495e-05', '6.023e-05', '6.023e-05', '6.403e-05', '6.023e-05', '6.672e-05']
INFO:root:err_norm_V: ['6.274e-05', '6.086e-05', '6.086e-05', '6.319e-05', '6.336e-05', '6.086e-05']
INFO:root:err_norm: ['6.384e-05', '6.055e-05', '6.055e-05', '6.361e-05', '6.179e-05', '6.379e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-1B
INFO:root:r: 32
INFO:root:#layer: 16, shape of W_k: torch.Size([2048, 512]) W_v: torch.Size([2048, 512])
INFO:root:Total number of parameters in W_k: 16777216, W_v: 16777216
INFO:root:err_norm_K: ['3.321e-05', '2.995e-05', '2.995e-05', '3.207e-05', '2.995e-05', '3.543e-05']
INFO:root:err_norm_V: ['1.308e-05', '1.241e-05', '1.241e-05', '1.380e-05', '1.353e-05', '1.241e-05']
INFO:root:err_norm: ['2.315e-05', '2.118e-05', '2.118e-05', '2.294e-05', '2.174e-05', '2.392e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.2-3B
INFO:root:r: 32
INFO:root:#layer: 28, shape of W_k: torch.Size([3072, 1024]) W_v: torch.Size([3072, 1024])
INFO:root:Total number of parameters in W_k: 88080384, W_v: 88080384
INFO:root:err_norm_K: ['1.654e-05', '1.558e-05', '1.558e-05', '1.622e-05', '1.558e-05', '1.714e-05']
INFO:root:err_norm_V: ['8.237e-06', '8.018e-06', '8.018e-06', '8.434e-06', '8.349e-06', '8.018e-06']
INFO:root:err_norm: ['1.239e-05', '1.180e-05', '1.180e-05', '1.233e-05', '1.196e-05', '1.258e-05']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/meta-llama/Llama-3.1-8B
INFO:root:r: 32
INFO:root:#layer: 32, shape of W_k: torch.Size([4096, 1024]) W_v: torch.Size([4096, 1024])
INFO:root:Total number of parameters in W_k: 134217728, W_v: 134217728
INFO:root:err_norm_K: ['1.231e-05', '1.168e-05', '1.168e-05', '1.209e-05', '1.168e-05', '1.275e-05']
INFO:root:err_norm_V: ['5.238e-06', '5.106e-06', '5.106e-06', '5.382e-06', '5.319e-06', '5.106e-06']
INFO:root:err_norm: ['8.772e-06', '8.393e-06', '8.393e-06', '8.736e-06', '8.500e-06', '8.926e-06']











INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
INFO:root:




INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.590e-04', '8.016e-04', '8.016e-04', '8.526e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.800e-04', '7.436e-04', '7.436e-04', '7.791e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.590e-04', '8.016e-04', '8.016e-04', '8.526e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.800e-04', '7.436e-04', '7.436e-04', '7.791e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.076e-04', '7.511e-04', '7.511e-04', '8.020e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.235e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.579e-04', '7.219e-04', '7.219e-04', '7.571e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.076e-04', '7.511e-04', '7.511e-04', '8.020e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.235e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.579e-04', '7.219e-04', '7.219e-04', '7.571e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.102e-04', '7.521e-04', '7.521e-04', '8.038e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.210e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.592e-04', '7.223e-04', '7.223e-04', '7.581e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.102e-04', '7.521e-04', '7.521e-04', '8.038e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.210e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.592e-04', '7.223e-04', '7.223e-04', '7.581e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.084e-03', '9.758e-04', '9.758e-04', '1.080e-03', '9.758e-04', '1.148e-03', '1.041e-03']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.209e-04', '7.339e-04', '7.000e-04', '7.116e-04']
INFO:root:err_norm: ['8.200e-04', '7.752e-04', '7.752e-04', '8.189e-04', '7.998e-04', '8.223e-04', '8.016e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.016e-03', '9.273e-04', '9.273e-04', '1.015e-03', '9.273e-04', '1.079e-03', '9.806e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.212e-04', '7.340e-04', '7.000e-04', '7.127e-04']
INFO:root:err_norm: ['8.105e-04', '7.692e-04', '7.692e-04', '8.105e-04', '7.928e-04', '8.155e-04', '7.942e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 72]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1244160, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['1.024e-03', '8.325e-04', '8.325e-04', '1.025e-03', '8.325e-04', '1.134e-03', '9.503e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.023e-04', '7.263e-04', '6.640e-04', '6.839e-04']
INFO:root:err_norm: ['7.910e-04', '7.099e-04', '7.099e-04', '7.903e-04', '7.552e-04', '7.921e-04', '7.565e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 84]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 1451520, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['9.626e-04', '8.034e-04', '8.034e-04', '9.639e-04', '8.034e-04', '1.066e-03', '8.992e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.031e-04', '7.264e-04', '6.640e-04', '6.856e-04']
INFO:root:err_norm: ['7.823e-04', '7.064e-04', '7.064e-04', '7.825e-04', '7.499e-04', '7.863e-04', '7.506e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.783e-04', '7.282e-04', '7.282e-04', '7.747e-04', '7.282e-04', '8.110e-04', '7.529e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.225e-04', '7.336e-04', '7.000e-04', '7.141e-04']
INFO:root:err_norm: ['7.454e-04', '7.121e-04', '7.121e-04', '7.449e-04', '7.313e-04', '7.476e-04', '7.307e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.330e-04', '6.884e-04', '6.884e-04', '7.288e-04', '6.884e-04', '7.625e-04', '7.075e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.233e-04', '7.336e-04', '7.000e-04', '7.158e-04']
INFO:root:err_norm: ['7.264e-04', '6.946e-04', '6.946e-04', '7.259e-04', '7.125e-04', '7.292e-04', '7.119e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.479e-04', '6.597e-04', '6.597e-04', '7.438e-04', '6.597e-04', '8.007e-04', '7.047e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.054e-04', '7.259e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.225e-04', '6.622e-04', '6.622e-04', '7.219e-04', '6.975e-04', '7.226e-04', '6.952e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.054e-04', '6.266e-04', '6.266e-04', '6.998e-04', '6.266e-04', '7.528e-04', '6.626e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.068e-04', '7.263e-04', '6.640e-04', '6.908e-04']
INFO:root:err_norm: ['7.043e-04', '6.465e-04', '6.465e-04', '7.035e-04', '6.797e-04', '7.054e-04', '6.776e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.604e-04', '8.016e-04', '8.016e-04', '8.532e-04', '8.016e-04', '8.991e-04', '8.223e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.338e-04', '7.000e-04', '7.176e-04']
INFO:root:err_norm: ['7.806e-04', '7.436e-04', '7.436e-04', '7.794e-04', '7.629e-04', '7.854e-04', '7.625e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.130e-04', '7.511e-04', '7.511e-04', '8.035e-04', '7.511e-04', '8.467e-04', '7.733e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.166e-04']
INFO:root:err_norm: ['7.603e-04', '7.219e-04', '7.219e-04', '7.579e-04', '7.412e-04', '7.629e-04', '7.409e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.133e-04', '7.521e-04', '7.521e-04', '8.045e-04', '7.521e-04', '8.489e-04', '7.738e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.238e-04', '7.338e-04', '7.000e-04', '7.167e-04']
INFO:root:err_norm: ['7.605e-04', '7.223e-04', '7.223e-04', '7.584e-04', '7.416e-04', '7.638e-04', '7.412e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.783e-04', '7.282e-04', '7.282e-04', '7.747e-04', '7.282e-04', '8.110e-04', '7.529e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.225e-04', '7.336e-04', '7.000e-04', '7.141e-04']
INFO:root:err_norm: ['7.454e-04', '7.121e-04', '7.121e-04', '7.449e-04', '7.313e-04', '7.476e-04', '7.307e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.441e-04', '6.872e-04', '6.872e-04', '7.385e-04', '6.872e-04', '7.814e-04', '7.106e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.230e-04', '7.334e-04', '7.000e-04', '7.150e-04']
INFO:root:err_norm: ['7.309e-04', '6.945e-04', '6.945e-04', '7.297e-04', '7.136e-04', '7.349e-04', '7.131e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.731e-04', '7.231e-04', '7.231e-04', '7.665e-04', '7.231e-04', '8.061e-04', '7.402e-04']
INFO:root:err_norm_V: ['7.206e-04', '7.000e-04', '7.000e-04', '7.243e-04', '7.336e-04', '7.000e-04', '7.178e-04']
INFO:root:err_norm: ['7.451e-04', '7.108e-04', '7.108e-04', '7.440e-04', '7.287e-04', '7.495e-04', '7.282e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.557e-04', '7.022e-04', '7.022e-04', '7.468e-04', '7.022e-04', '7.839e-04', '7.199e-04']
INFO:root:err_norm_V: ['7.209e-04', '7.000e-04', '7.000e-04', '7.244e-04', '7.337e-04', '7.000e-04', '7.173e-04']
INFO:root:err_norm: ['7.371e-04', '7.011e-04', '7.011e-04', '7.349e-04', '7.190e-04', '7.392e-04', '7.185e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.495e-04', '6.996e-04', '6.996e-04', '7.432e-04', '6.996e-04', '7.826e-04', '7.169e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.241e-04', '7.337e-04', '7.000e-04', '7.174e-04']
INFO:root:err_norm: ['7.341e-04', '6.998e-04', '6.998e-04', '7.330e-04', '7.178e-04', '7.386e-04', '7.172e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.330e-04', '6.884e-04', '6.884e-04', '7.288e-04', '6.884e-04', '7.625e-04', '7.075e-04']
INFO:root:err_norm_V: ['7.207e-04', '7.000e-04', '7.000e-04', '7.233e-04', '7.336e-04', '7.000e-04', '7.158e-04']
INFO:root:err_norm: ['7.264e-04', '6.946e-04', '6.946e-04', '7.259e-04', '7.125e-04', '7.292e-04', '7.119e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 8
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.224e-04', '6.727e-04', '6.727e-04', '7.165e-04', '6.727e-04', '7.559e-04', '6.907e-04']
INFO:root:err_norm_V: ['7.208e-04', '7.000e-04', '7.000e-04', '7.239e-04', '7.337e-04', '7.000e-04', '7.169e-04']
INFO:root:err_norm: ['7.215e-04', '6.873e-04', '6.873e-04', '7.204e-04', '7.052e-04', '7.261e-04', '7.047e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['8.268e-04', '7.245e-04', '7.245e-04', '8.170e-04', '7.245e-04', '8.879e-04', '7.647e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.082e-04', '7.266e-04', '6.640e-04', '6.939e-04']
INFO:root:err_norm: ['7.565e-04', '6.899e-04', '6.899e-04', '7.548e-04', '7.257e-04', '7.600e-04', '7.242e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.802e-04', '6.760e-04', '6.760e-04', '7.689e-04', '6.760e-04', '8.362e-04', '7.192e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.267e-04', '6.640e-04', '6.919e-04']
INFO:root:err_norm: ['7.364e-04', '6.691e-04', '6.691e-04', '7.336e-04', '7.050e-04', '7.378e-04', '7.036e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 4, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.818e-04', '6.800e-04', '6.800e-04', '7.715e-04', '6.800e-04', '8.382e-04', '7.224e-04']
INFO:root:err_norm_V: ['7.036e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.265e-04', '6.640e-04', '6.913e-04']
INFO:root:err_norm: ['7.371e-04', '6.709e-04', '6.709e-04', '7.348e-04', '7.066e-04', '7.386e-04', '7.046e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 8, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.479e-04', '6.597e-04', '6.597e-04', '7.438e-04', '6.597e-04', '8.007e-04', '7.047e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.054e-04', '7.259e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.225e-04', '6.622e-04', '6.622e-04', '7.219e-04', '6.975e-04', '7.226e-04', '6.952e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 144]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2488320, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 8, 'uniform_start_point': 0, 'uniform_step': 4, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.149e-04', '6.205e-04', '6.205e-04', '7.091e-04', '6.205e-04', '7.712e-04', '6.645e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.056e-04', '7.257e-04', '6.640e-04', '6.880e-04']
INFO:root:err_norm: ['7.085e-04', '6.454e-04', '6.454e-04', '7.071e-04', '6.806e-04', '7.099e-04', '6.779e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 1, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.444e-04', '6.579e-04', '6.579e-04', '7.354e-04', '6.579e-04', '7.960e-04', '6.908e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.084e-04', '7.265e-04', '6.640e-04', '6.942e-04']
INFO:root:err_norm: ['7.225e-04', '6.611e-04', '6.611e-04', '7.210e-04', '6.945e-04', '7.256e-04', '6.926e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 2, 'top_k_rope_dim': 0, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.274e-04', '6.376e-04', '6.376e-04', '7.163e-04', '6.376e-04', '7.742e-04', '6.718e-04']
INFO:root:err_norm_V: ['7.037e-04', '6.640e-04', '6.640e-04', '7.083e-04', '7.266e-04', '6.640e-04', '6.933e-04']
INFO:root:err_norm: ['7.148e-04', '6.517e-04', '6.517e-04', '7.121e-04', '6.851e-04', '7.154e-04', '6.832e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 3, 'top_k_rope_dim': 2, 'last_k_rope_dim': 2, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.215e-04', '6.359e-04', '6.359e-04', '7.131e-04', '6.359e-04', '7.727e-04', '6.696e-04']
INFO:root:err_norm_V: ['7.035e-04', '6.640e-04', '6.640e-04', '7.080e-04', '7.265e-04', '6.640e-04', '6.930e-04']
INFO:root:err_norm: ['7.119e-04', '6.509e-04', '6.509e-04', '7.104e-04', '6.842e-04', '7.147e-04', '6.821e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 4, 'top_k_rope_dim': 4, 'last_k_rope_dim': 0, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['7.054e-04', '6.266e-04', '6.266e-04', '6.998e-04', '6.266e-04', '7.528e-04', '6.626e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.068e-04', '7.263e-04', '6.640e-04', '6.908e-04']
INFO:root:err_norm: ['7.043e-04', '6.465e-04', '6.465e-04', '7.035e-04', '6.797e-04', '7.054e-04', '6.776e-04']
INFO:root:



INFO:root:model_path: /home/binguo/data/models/HuggingFaceTB/SmolLM-135M
INFO:root:r: 16
INFO:root:#layer: 30, shape of W_k: torch.Size([576, 168]) W_v: torch.Size([576, 192])
INFO:root:Total number of parameters in W_k: 2903040, W_v: 3317760
INFO:root:rope_cfg: {'partial_rope_version': 5, 'top_k_rope_dim': 0, 'last_k_rope_dim': 4, 'uniform_start_point': 0, 'uniform_step': 8, 'qk_tensor_path': '/home/taoji/data/MLA-FT/utils/qk_tensor_135M.pkl', 'n_gqa_group': 3}
INFO:root:kwargs: {'head_dim': 64, 'head_num': 3}
INFO:root:err_norm_K: ['6.951e-04', '6.113e-04', '6.113e-04', '6.877e-04', '6.113e-04', '7.463e-04', '6.464e-04']
INFO:root:err_norm_V: ['7.034e-04', '6.640e-04', '6.640e-04', '7.072e-04', '7.264e-04', '6.640e-04', '6.916e-04']
INFO:root:err_norm: ['6.995e-04', '6.394e-04', '6.394e-04', '6.981e-04', '6.726e-04', '7.024e-04', '6.705e-04']
